{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Notebook para Tratamento de Valores Nulos**\n",
    "\n",
    "**Introdução:**\n",
    "Neste notebook, iremos remover, tratar e substituir valores nulos de nossa bade de dados. Os atributos utlizados foram selecionados criteriozamente utilizando como base o método CAPTO para selecionar os atributos mais relevantes para a classificação de pessoas que possam possuir depressão. Os dados utilizados serão provenientes da Pesquisa Nacional de Saúde (PNS) de 2019.\n",
    "\n",
    "**Objetivos:**\n",
    "O principal objetivo deste notebook é remover, tratar e substituir por completo dados nulos de nossa base, deixando a base preenchida por completo. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas Utilizadas\n",
    "As principais bibliotecas utilizadas nesta etapa são:\n",
    "- Sidetable: Auxilia na identificação rápida de valores faltantes e frequências de valores categóricos.\n",
    "- Pandas Profiling: Faz uma análise exploratória automática dos dados, gerando insights sobre problemas nos dados.\n",
    "- NumPy: Biblioteca fundamental para computação científica em Python.\n",
    "- Pandas: Biblioteca popular para análise de dados.\n",
    "- IPython Widgets: Permite interatividade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import sidetable \n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "from ipywidgets import interact, widgets \n",
    "\n",
    "from sklearn.preprocessing import scale, minmax_scale, power_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(\n",
    "    context = 'talk', \n",
    "    style='ticks',\n",
    "    font_scale= 8,\n",
    "    rc= {\n",
    "        'figure.figsize': (12,8) \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratando Valores Nulos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Importando base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\maype\\OneDrive\\Área de Trabalho\\projects\\projeto-aprendizado-de-maquina\\Data\\base_tratada.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sexo</th>\n",
       "      <th>Apoio_Familiar</th>\n",
       "      <th>Apoio_de_Amigos</th>\n",
       "      <th>Tipo_de_Trabalho</th>\n",
       "      <th>Trabalhador_Nao_Remunerado</th>\n",
       "      <th>Horas_Trabalhadas_Noite</th>\n",
       "      <th>Freq_Trabalho_Noite</th>\n",
       "      <th>Curso_Mais_Elevado</th>\n",
       "      <th>Diagnostico_Depressao</th>\n",
       "      <th>...</th>\n",
       "      <th>idade</th>\n",
       "      <th>trabalhou</th>\n",
       "      <th>horas_trabalhadas_total</th>\n",
       "      <th>doencas_cronicas</th>\n",
       "      <th>saneamento_basico</th>\n",
       "      <th>moradia_vulneravel</th>\n",
       "      <th>tempo_total_exercicio</th>\n",
       "      <th>frequencia_exercicio</th>\n",
       "      <th>doses_bebida_alcoolica</th>\n",
       "      <th>freq_bebida_alcoolica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Sexo  Apoio_Familiar  Apoio_de_Amigos  Tipo_de_Trabalho  \\\n",
       "0           0   2.0             3.0              0.0               6.0   \n",
       "1           1   2.0             1.0              1.0               3.0   \n",
       "2           2   2.0             1.0              0.0               3.0   \n",
       "3           3   2.0             3.0              0.0               3.0   \n",
       "4           4   2.0             2.0              1.0               6.0   \n",
       "\n",
       "   Trabalhador_Nao_Remunerado  Horas_Trabalhadas_Noite  Freq_Trabalho_Noite  \\\n",
       "0                         NaN                      NaN                  NaN   \n",
       "1                         NaN                      NaN                  NaN   \n",
       "2                         NaN                      NaN                  NaN   \n",
       "3                         NaN                      NaN                  NaN   \n",
       "4                         NaN                      NaN                  NaN   \n",
       "\n",
       "   Curso_Mais_Elevado  Diagnostico_Depressao  ...  idade  trabalhou  \\\n",
       "0                 5.0                    1.0  ...   55.0        1.0   \n",
       "1                10.0                    2.0  ...   45.0        1.0   \n",
       "2                 4.0                    2.0  ...   58.0        1.0   \n",
       "3                10.0                    2.0  ...   41.0        1.0   \n",
       "4                 7.0                    2.0  ...   52.0        1.0   \n",
       "\n",
       "   horas_trabalhadas_total  doencas_cronicas  saneamento_basico  \\\n",
       "0                     40.0                 1                  2   \n",
       "1                     36.0                 2                  2   \n",
       "2                      6.0                 2                  2   \n",
       "3                     16.0                 2                  2   \n",
       "4                     48.0                 1                  2   \n",
       "\n",
       "   moradia_vulneravel  tempo_total_exercicio  frequencia_exercicio  \\\n",
       "0                   2                    0.5                   1.0   \n",
       "1                   2                    NaN                   NaN   \n",
       "2                   2                    1.0                   3.0   \n",
       "3                   2                    2.0                   7.0   \n",
       "4                   2                    NaN                   0.0   \n",
       "\n",
       "   doses_bebida_alcoolica  freq_bebida_alcoolica  \n",
       "0                     NaN                    2.0  \n",
       "1                     7.0                    3.0  \n",
       "2                     NaN                    1.0  \n",
       "3                     NaN                    1.0  \n",
       "4                     NaN                    1.0  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Informações sobre a base "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40359 entries, 0 to 40358\n",
      "Data columns (total 70 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Unnamed: 0                       40359 non-null  int64  \n",
      " 1   Sexo                             40359 non-null  float64\n",
      " 2   Apoio_Familiar                   40359 non-null  float64\n",
      " 3   Apoio_de_Amigos                  40359 non-null  float64\n",
      " 4   Tipo_de_Trabalho                 26285 non-null  float64\n",
      " 5   Trabalhador_Nao_Remunerado       295 non-null    float64\n",
      " 6   Horas_Trabalhadas_Noite          3145 non-null   float64\n",
      " 7   Freq_Trabalho_Noite              3145 non-null   float64\n",
      " 8   Curso_Mais_Elevado               36596 non-null  float64\n",
      " 9   Diagnostico_Depressao            40359 non-null  float64\n",
      " 10  A005010                          40359 non-null  float64\n",
      " 11  Estado_de_Saude                  40359 non-null  float64\n",
      " 12  Pratica_Exercicio                40359 non-null  float64\n",
      " 13  Exercicio_Mais_Frequente         14434 non-null  float64\n",
      " 14  Motivo_Impedimento_Atividades    4498 non-null   float64\n",
      " 15  Ultima_Consulta_Medica           40359 non-null  float64\n",
      " 16  Procura_Atendimento_Saude        40359 non-null  float64\n",
      " 17  Motivo_Atendimento_Saude         9178 non-null   float64\n",
      " 18  Orientacoes_Saude                4780 non-null   float64\n",
      " 19  Problemas_Sono                   40359 non-null  float64\n",
      " 20  Consumo_Arroz_Macarrao           40359 non-null  float64\n",
      " 21  Consumo_Batata                   40359 non-null  float64\n",
      " 22  Consumo_Feijao                   40359 non-null  float64\n",
      " 23  Consumo_Carne                    40359 non-null  float64\n",
      " 24  Consumo_Ovo                      40359 non-null  float64\n",
      " 25  Consumo_Verduras_1               40359 non-null  float64\n",
      " 26  Consumo_Verduras_2               40359 non-null  float64\n",
      " 27  Consumo_Verduras_3               40359 non-null  float64\n",
      " 28  Consumo_Frutas_1                 40359 non-null  float64\n",
      " 29  Consumo_Frutas_2                 40359 non-null  float64\n",
      " 30  Consumo_Leite                    40359 non-null  float64\n",
      " 31  Consumo_Castanhas                40359 non-null  float64\n",
      " 32  Consumo_Refrigerante             40359 non-null  float64\n",
      " 33  Consumo_Suco_Caixinha            40359 non-null  float64\n",
      " 34  Consumo_Bebida_Achocolatada      40359 non-null  float64\n",
      " 35  Consumo_Salgadinho_Biscoito      40359 non-null  float64\n",
      " 36  Consumo_Biscoito_Doce            40359 non-null  float64\n",
      " 37  Consumo_Sobremesa                40359 non-null  float64\n",
      " 38  Consumo_Embutidos                40359 non-null  float64\n",
      " 39  Consumo_Pao                      40359 non-null  float64\n",
      " 40  Consumo_Molhos_Industrializados  40359 non-null  float64\n",
      " 41  Consumo_Alimentos_Prontos        40359 non-null  float64\n",
      " 42  Freq_Consumo_Feijao              40359 non-null  float64\n",
      " 43  Freq_Consumo_Verduras            40359 non-null  float64\n",
      " 44  Tipo_Verdura_Costuma_Comer       22162 non-null  float64\n",
      " 45  Freq_Consumo_Carne_Vermelha      40359 non-null  float64\n",
      " 46  Freq_Consumo_Frango              40359 non-null  float64\n",
      " 47  Freq_Consumo_Peixe               40359 non-null  float64\n",
      " 48  Freq_Consumo_Suco_Caixinha       40359 non-null  float64\n",
      " 49  Freq_Consumo_Suco_Natural        40359 non-null  float64\n",
      " 50  Freq_Consumo_Frutas              40359 non-null  float64\n",
      " 51  Freq_Comer_Frutas_Dia            18957 non-null  float64\n",
      " 52  Freq_Consumo_Refrigerante        40359 non-null  float64\n",
      " 53  Freq_Consumo_Leite               40359 non-null  float64\n",
      " 54  Tipo_Leite                       27706 non-null  float64\n",
      " 55  Freq_Consumo_Doces               40359 non-null  float64\n",
      " 56  Freq_Substituicao_Refeicao       40359 non-null  float64\n",
      " 57  peso_consolidado                 40359 non-null  float64\n",
      " 58  altura_consolidada               40359 non-null  float64\n",
      " 59  renda_total                      40359 non-null  float64\n",
      " 60  idade                            40359 non-null  float64\n",
      " 61  trabalhou                        40359 non-null  float64\n",
      " 62  horas_trabalhadas_total          40359 non-null  float64\n",
      " 63  doencas_cronicas                 40359 non-null  int64  \n",
      " 64  saneamento_basico                40359 non-null  int64  \n",
      " 65  moradia_vulneravel               40359 non-null  int64  \n",
      " 66  tempo_total_exercicio            14434 non-null  float64\n",
      " 67  frequencia_exercicio             14914 non-null  float64\n",
      " 68  doses_bebida_alcoolica           10983 non-null  float64\n",
      " 69  freq_bebida_alcoolica            40359 non-null  float64\n",
      "dtypes: float64(66), int64(4)\n",
      "memory usage: 21.6 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Identificando valores nulos \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                    0\n",
       "Sexo                          0\n",
       "Apoio_Familiar                0\n",
       "Apoio_de_Amigos               0\n",
       "Tipo_de_Trabalho          14074\n",
       "                          ...  \n",
       "moradia_vulneravel            0\n",
       "tempo_total_exercicio     25925\n",
       "frequencia_exercicio      25445\n",
       "doses_bebida_alcoolica    29376\n",
       "freq_bebida_alcoolica         0\n",
       "Length: 70, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Valores absolutos\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_e1dc9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e1dc9_level0_col0\" class=\"col_heading level0 col0\" >% Valores Nulos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e1dc9_level0_row0\" class=\"row_heading level0 row0\" >Trabalhador_Nao_Remunerado</th>\n",
       "      <td id=\"T_e1dc9_row0_col0\" class=\"data row0 col0\" >99.27%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1dc9_level0_row1\" class=\"row_heading level0 row1\" >Horas_Trabalhadas_Noite</th>\n",
       "      <td id=\"T_e1dc9_row1_col0\" class=\"data row1 col0\" >92.21%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1dc9_level0_row2\" class=\"row_heading level0 row2\" >Freq_Trabalho_Noite</th>\n",
       "      <td id=\"T_e1dc9_row2_col0\" class=\"data row2 col0\" >92.21%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1dc9_level0_row3\" class=\"row_heading level0 row3\" >Motivo_Impedimento_Atividades</th>\n",
       "      <td id=\"T_e1dc9_row3_col0\" class=\"data row3 col0\" >88.86%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1dc9_level0_row4\" class=\"row_heading level0 row4\" >Orientacoes_Saude</th>\n",
       "      <td id=\"T_e1dc9_row4_col0\" class=\"data row4 col0\" >88.16%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1dc9_level0_row5\" class=\"row_heading level0 row5\" >Motivo_Atendimento_Saude</th>\n",
       "      <td id=\"T_e1dc9_row5_col0\" class=\"data row5 col0\" >77.26%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1dc9_level0_row6\" class=\"row_heading level0 row6\" >doses_bebida_alcoolica</th>\n",
       "      <td id=\"T_e1dc9_row6_col0\" class=\"data row6 col0\" >72.79%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1dc9_level0_row7\" class=\"row_heading level0 row7\" >Exercicio_Mais_Frequente</th>\n",
       "      <td id=\"T_e1dc9_row7_col0\" class=\"data row7 col0\" >64.24%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1dc9_level0_row8\" class=\"row_heading level0 row8\" >tempo_total_exercicio</th>\n",
       "      <td id=\"T_e1dc9_row8_col0\" class=\"data row8 col0\" >64.24%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1dc9_level0_row9\" class=\"row_heading level0 row9\" >frequencia_exercicio</th>\n",
       "      <td id=\"T_e1dc9_row9_col0\" class=\"data row9 col0\" >63.05%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1dc9_level0_row10\" class=\"row_heading level0 row10\" >Freq_Comer_Frutas_Dia</th>\n",
       "      <td id=\"T_e1dc9_row10_col0\" class=\"data row10 col0\" >53.03%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1dc9_level0_row11\" class=\"row_heading level0 row11\" >Tipo_Verdura_Costuma_Comer</th>\n",
       "      <td id=\"T_e1dc9_row11_col0\" class=\"data row11 col0\" >45.09%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1dc9_level0_row12\" class=\"row_heading level0 row12\" >Tipo_de_Trabalho</th>\n",
       "      <td id=\"T_e1dc9_row12_col0\" class=\"data row12 col0\" >34.87%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1dc9_level0_row13\" class=\"row_heading level0 row13\" >Tipo_Leite</th>\n",
       "      <td id=\"T_e1dc9_row13_col0\" class=\"data row13 col0\" >31.35%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1dc9_level0_row14\" class=\"row_heading level0 row14\" >Curso_Mais_Elevado</th>\n",
       "      <td id=\"T_e1dc9_row14_col0\" class=\"data row14 col0\" >9.32%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x201035d4150>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Porcentagem destes valores \n",
    "\n",
    "# Calcular a porcentagem de valores nulos apenas nas colunas que têm valores nulos\n",
    "porcentagem_nulos = (df.isna().sum() / df.shape[0])\n",
    "\n",
    "# Filtrar apenas as colunas que têm valores nulos\n",
    "porcentagem_nulos_filtrada = porcentagem_nulos[porcentagem_nulos > 0]\n",
    "\n",
    "df_nulos=(\n",
    "porcentagem_nulos_filtrada.to_frame(\"% Valores Nulos\")\n",
    ".sort_values(\"% Valores Nulos\", ascending=False)\n",
    ")\n",
    "\n",
    "\n",
    "df_nulos.style.format('{:1.2%}', subset=['% Valores Nulos'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removendo Colunas\n",
    "> Iremos remover todas as colunas com quantidade de valores nulos maior que 70%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Trabalhador_Nao_Remunerado', 'Horas_Trabalhadas_Noite', 'Freq_Trabalho_Noite', 'Motivo_Impedimento_Atividades', 'Orientacoes_Saude', 'Motivo_Atendimento_Saude', 'doses_bebida_alcoolica'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Sexo', 'Apoio_Familiar', 'Apoio_de_Amigos',\n",
       "       'Tipo_de_Trabalho', 'Curso_Mais_Elevado', 'Diagnostico_Depressao',\n",
       "       'A005010', 'Estado_de_Saude', 'Pratica_Exercicio',\n",
       "       'Exercicio_Mais_Frequente', 'Ultima_Consulta_Medica',\n",
       "       'Procura_Atendimento_Saude', 'Problemas_Sono', 'Consumo_Arroz_Macarrao',\n",
       "       'Consumo_Batata', 'Consumo_Feijao', 'Consumo_Carne', 'Consumo_Ovo',\n",
       "       'Consumo_Verduras_1', 'Consumo_Verduras_2', 'Consumo_Verduras_3',\n",
       "       'Consumo_Frutas_1', 'Consumo_Frutas_2', 'Consumo_Leite',\n",
       "       'Consumo_Castanhas', 'Consumo_Refrigerante', 'Consumo_Suco_Caixinha',\n",
       "       'Consumo_Bebida_Achocolatada', 'Consumo_Salgadinho_Biscoito',\n",
       "       'Consumo_Biscoito_Doce', 'Consumo_Sobremesa', 'Consumo_Embutidos',\n",
       "       'Consumo_Pao', 'Consumo_Molhos_Industrializados',\n",
       "       'Consumo_Alimentos_Prontos', 'Freq_Consumo_Feijao',\n",
       "       'Freq_Consumo_Verduras', 'Tipo_Verdura_Costuma_Comer',\n",
       "       'Freq_Consumo_Carne_Vermelha', 'Freq_Consumo_Frango',\n",
       "       'Freq_Consumo_Peixe', 'Freq_Consumo_Suco_Caixinha',\n",
       "       'Freq_Consumo_Suco_Natural', 'Freq_Consumo_Frutas',\n",
       "       'Freq_Comer_Frutas_Dia', 'Freq_Consumo_Refrigerante',\n",
       "       'Freq_Consumo_Leite', 'Tipo_Leite', 'Freq_Consumo_Doces',\n",
       "       'Freq_Substituicao_Refeicao', 'peso_consolidado', 'altura_consolidada',\n",
       "       'renda_total', 'idade', 'trabalhou', 'horas_trabalhadas_total',\n",
       "       'doencas_cronicas', 'saneamento_basico', 'moradia_vulneravel',\n",
       "       'tempo_total_exercicio', 'frequencia_exercicio',\n",
       "       'freq_bebida_alcoolica'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conferindo se as colunas foram removidas\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prenchendo Valores\n",
    "> Nesta etapa iremos utilizar da própria lógica do questionário da PNS para tentar preencher o máximo de valores nulos possiveis. \n",
    "> Nos atributos que ainda restarem valores nulos iremos utilizar *estatisticas descritivas* e modelos de *machine learning* para preencher os valores restantes em nossa base de dados. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> Vamos preencher algumas colunas com \"Não respondeu\" de acordo com a logica do questionário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exercicio_Mais_Frequente      float64\n",
       "tempo_total_exercicio         float64\n",
       "frequencia_exercicio          float64\n",
       "Freq_Comer_Frutas_Dia         float64\n",
       "Tipo_Verdura_Costuma_Comer    float64\n",
       "Tipo_de_Trabalho              float64\n",
       "Tipo_Leite                    float64\n",
       "Curso_Mais_Elevado            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando Tipos de dados\n",
    "df[[\t\n",
    "'Exercicio_Mais_Frequente',\t\n",
    "'tempo_total_exercicio',\t\n",
    "'frequencia_exercicio',\t\n",
    "'Freq_Comer_Frutas_Dia',\t\n",
    "'Tipo_Verdura_Costuma_Comer',\t\n",
    "'Tipo_de_Trabalho',\t\n",
    "'Tipo_Leite',\t\n",
    "'Curso_Mais_Elevado']].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos mudar o tipo de dados de \"Tipo_de_Trabalho\", \"Curso_Mais_Elevado\", \"Exercicio_Mais_Frequente\",\n",
    "# \"Tipo_Verdura_Costuma_Comer\" e \"Tipo_Leite\" para categorico. \n",
    "\n",
    "colunas_para_converter = ['Tipo_de_Trabalho', 'Curso_Mais_Elevado', 'Exercicio_Mais_Frequente', 'Tipo_Verdura_Costuma_Comer', 'Tipo_Leite']\n",
    "df[colunas_para_converter] = df[colunas_para_converter].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipo_de_Trabalho              category\n",
      "Curso_Mais_Elevado            category\n",
      "Exercicio_Mais_Frequente      category\n",
      "Tipo_Verdura_Costuma_Comer    category\n",
      "Freq_Comer_Frutas_Dia          float64\n",
      "Tipo_Leite                    category\n",
      "tempo_total_exercicio          float64\n",
      "frequencia_exercicio           float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Verificando novamente \n",
    "valores_nulos = df.isnull().sum()\n",
    "\n",
    "colunas_com_nulos = valores_nulos[valores_nulos > 0].index\n",
    "\n",
    "tipos_dados_colunas_com_nulos = df[colunas_com_nulos].dtypes\n",
    "print(tipos_dados_colunas_com_nulos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipo de Trabalho "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        6.0\n",
       "1        3.0\n",
       "2        3.0\n",
       "3        3.0\n",
       "4        6.0\n",
       "        ... \n",
       "40354    6.0\n",
       "40355    6.0\n",
       "40356    3.0\n",
       "40357    3.0\n",
       "40358    6.0\n",
       "Name: Tipo_de_Trabalho, Length: 40359, dtype: category\n",
       "Categories (7, float64): [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tipo_de_Trabalho']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertendo a coluna 'Tipo_de_Trabalho' para tipo de dados string\n",
    "df['Tipo_de_Trabalho'] = df['Tipo_de_Trabalho'].astype('string')\n",
    "\n",
    "# Aplicando a lógica\n",
    "for index, row in df.iterrows():\n",
    "    if row['trabalhou'] == 1 and pd.isna(row['Tipo_de_Trabalho']):\n",
    "        df.at[index, 'Tipo_de_Trabalho'] = None\n",
    "    elif row['trabalhou'] == 2 and pd.isna(row['Tipo_de_Trabalho']):\n",
    "        df.at[index, 'Tipo_de_Trabalho'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retornando variável para seu tipo original \n",
    "df['Tipo_de_Trabalho'] = df['Tipo_de_Trabalho'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tipo_de_Trabalho'].isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        6.0\n",
       "1        3.0\n",
       "2        3.0\n",
       "3        3.0\n",
       "4        6.0\n",
       "        ... \n",
       "40354    6.0\n",
       "40355    6.0\n",
       "40356    3.0\n",
       "40357    3.0\n",
       "40358    6.0\n",
       "Name: Tipo_de_Trabalho, Length: 40359, dtype: category\n",
       "Categories (8, string): [0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tipo_de_Trabalho']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercicio_Mais_Frequente, tempo_total_exercicio, frequencia_exercicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertendo as colunas para tipo de dados string\n",
    "df['Exercicio_Mais_Frequente'] = df['Exercicio_Mais_Frequente'].astype('string')\n",
    "\n",
    "# Aplicando a lógica\n",
    "for index, row in df.iterrows():\n",
    "    if row['Pratica_Exercicio'] == 1 and pd.isna(row['Exercicio_Mais_Frequente']):\n",
    "        df.at[index, 'Exercicio_Mais_Frequente'] = None\n",
    "    elif row['Pratica_Exercicio'] == 2 and pd.isna(row['Exercicio_Mais_Frequente']):\n",
    "        df.at[index, 'Exercicio_Mais_Frequente'] = '0'\n",
    "    \n",
    "    if row['Pratica_Exercicio'] == 1 and pd.isna(row['tempo_total_exercicio']):\n",
    "        df.at[index, 'tempo_total_exercicio'] = None\n",
    "    elif row['Pratica_Exercicio'] == 2 and pd.isna(row['tempo_total_exercicio']):\n",
    "        df.at[index, 'tempo_total_exercicio'] = 0\n",
    "    \n",
    "    if row['Pratica_Exercicio'] == 1 and pd.isna(row['frequencia_exercicio']):\n",
    "        df.at[index, 'frequencia_exercicio'] = None\n",
    "    elif row['Pratica_Exercicio'] == 2 and pd.isna(row['frequencia_exercicio']):\n",
    "        df.at[index, 'frequencia_exercicio'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exercicio_Mais_Frequente    480\n",
       "tempo_total_exercicio       480\n",
       "frequencia_exercicio          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Exercicio_Mais_Frequente','tempo_total_exercicio', 'frequencia_exercicio' ]].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retornando variável para seu tipo original \n",
    "df['Exercicio_Mais_Frequente'] = df['Exercicio_Mais_Frequente'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freq_Comer_Frutas_Dia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preenchendo as linhas onde 'Freq_Consumo_Frutas' é igual a 0\n",
    "df.loc[df['Freq_Consumo_Frutas'] == 0, 'Freq_Comer_Frutas_Dia'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17194"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Freq_Comer_Frutas_Dia'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipo_Verdura_Costuma_Comer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tipo_Verdura_Costuma_Comer'] = df['Tipo_Verdura_Costuma_Comer'].astype('string')\n",
    "\n",
    "# Preenchendo as linhas onde 'Freq_Consumo_Verduras' é igual a 0\n",
    "df.loc[df['Freq_Consumo_Verduras'] == 0, 'Tipo_Verdura_Costuma_Comer'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retornando variavel para seu tipo original \n",
    "df['Tipo_Verdura_Costuma_Comer'] = df['Tipo_Verdura_Costuma_Comer'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15411"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tipo_Verdura_Costuma_Comer'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipo_Leite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tipo_Leite'] = df['Tipo_Leite'].astype('string')\n",
    "\n",
    "# Preenchendo as linhas onde 'Freq_Consumo_Leite' é igual a 0\n",
    "df.loc[df['Freq_Consumo_Leite'] == 0, 'Tipo_Leite'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retornando variável para seu tipo original \n",
    "df['Tipo_Leite'] = df['Tipo_Leite'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conferindo quantidade de valores nulos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_2c051\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_2c051_level0_col0\" class=\"col_heading level0 col0\" >% Valores Nulos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2c051_level0_row0\" class=\"row_heading level0 row0\" >Freq_Comer_Frutas_Dia</th>\n",
       "      <td id=\"T_2c051_row0_col0\" class=\"data row0 col0\" >42.60%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2c051_level0_row1\" class=\"row_heading level0 row1\" >Tipo_Verdura_Costuma_Comer</th>\n",
       "      <td id=\"T_2c051_row1_col0\" class=\"data row1 col0\" >38.18%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2c051_level0_row2\" class=\"row_heading level0 row2\" >Curso_Mais_Elevado</th>\n",
       "      <td id=\"T_2c051_row2_col0\" class=\"data row2 col0\" >9.32%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2c051_level0_row3\" class=\"row_heading level0 row3\" >Exercicio_Mais_Frequente</th>\n",
       "      <td id=\"T_2c051_row3_col0\" class=\"data row3 col0\" >1.19%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2c051_level0_row4\" class=\"row_heading level0 row4\" >tempo_total_exercicio</th>\n",
       "      <td id=\"T_2c051_row4_col0\" class=\"data row4 col0\" >1.19%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2010ef1ee90>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Porcentagem destes valores \n",
    "\n",
    "# Calcular a porcentagem de valores nulos apenas nas colunas que têm valores nulos\n",
    "porcentagem_nulos = (df.isna().sum() / df.shape[0])\n",
    "\n",
    "# Filtrar apenas as colunas que têm valores nulos\n",
    "porcentagem_nulos_filtrada = porcentagem_nulos[porcentagem_nulos > 0]\n",
    "\n",
    "df_nulos=(\n",
    "porcentagem_nulos_filtrada.to_frame(\"% Valores Nulos\")\n",
    ".sort_values(\"% Valores Nulos\", ascending=False)\n",
    ")\n",
    "\n",
    "\n",
    "df_nulos.style.format('{:1.2%}', subset=['% Valores Nulos'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Preenchimento de Valores Ausentes usando KNN**\n",
    "\n",
    "Neste código, foram utilizados os seguintes passos para preencher valores ausentes em colunas numéricas usando o algoritmo KNN:\n",
    "\n",
    "1. **Seleção das colunas numéricas:** Foram selecionadas as colunas 'Freq_Comer_Frutas_Dia' e 'tempo_total_exercicio' do DataFrame para preenchimento.\n",
    "\n",
    "2. **Criação do imputer KNN:** Foi criado um objeto KNNImputer com n_neighbors=5. Isso significa que o algoritmo considerará os 5 vizinhos mais próximos para calcular o valor de imputação.\n",
    "\n",
    "3. **Preenchimento dos valores ausentes:** O método fit_transform do KNNImputer foi aplicado às colunas numéricas selecionadas do DataFrame. Isso ajusta o imputer aos dados e, em seguida, preenche os valores ausentes usando o algoritmo KNN.\n",
    "\n",
    "Esse procedimento é útil para lidar com valores ausentes em conjuntos de dados numéricos, preenchendo-os de forma inteligente com base nas características dos dados existentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maype\\AppData\\Local\\Temp\\ipykernel_9456\\1026276407.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(moda, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Selecionar as colunas categóricas para preenchimento com moda\n",
    "cols_categoricas = ['Exercicio_Mais_Frequente', 'Tipo_Verdura_Costuma_Comer', 'Curso_Mais_Elevado']\n",
    "\n",
    "# Selecionar as colunas numéricas para preenchimento com KNN\n",
    "cols_numericas = ['Freq_Comer_Frutas_Dia', 'tempo_total_exercicio']\n",
    "\n",
    "# Preencher os valores ausentes com a moda para colunas categóricas\n",
    "for col in cols_categoricas:\n",
    "    moda = df[col].mode()[0]\n",
    "    df[col].fillna(moda, inplace=True)\n",
    "\n",
    "# Criar um imputer KNN para as colunas numéricas\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# Preencher os valores ausentes com KNN para colunas numéricas\n",
    "df[cols_numericas] = knn_imputer.fit_transform(df[cols_numericas])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "continuous is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m acuracias_por_coluna \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m cols_numericas \u001b[38;5;241m+\u001b[39m cols_categoricas:\n\u001b[1;32m---> 12\u001b[0m     report \u001b[38;5;241m=\u001b[39m \u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_true_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_filled_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     acuracias_por_coluna[col] \u001b[38;5;241m=\u001b[39m report[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Imprimir resultados\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:2604\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2469\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m   2470\u001b[0m     {\n\u001b[0;32m   2471\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2495\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2496\u001b[0m ):\n\u001b[0;32m   2497\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n\u001b[0;32m   2498\u001b[0m \n\u001b[0;32m   2499\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2601\u001b[0m \u001b[38;5;124;03m    <BLANKLINE>\u001b[39;00m\n\u001b[0;32m   2602\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2604\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2606\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2607\u001b[0m         labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:105\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# No metrics support \"multiclass-multioutput\" format\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-indicator\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    108\u001b[0m     xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred)\n",
      "\u001b[1;31mValueError\u001b[0m: continuous is not supported"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Calcular os valores verdadeiros (DataFrame original sem os valores ausentes)\n",
    "df_true_values = df.dropna()\n",
    "\n",
    "# Calcular os valores preenchidos (DataFrame após preenchimento dos valores ausentes)\n",
    "df_filled_values = df.copy()\n",
    "\n",
    "# Acurácia por coluna\n",
    "acuracias_por_coluna = {}\n",
    "for col in cols_numericas + cols_categoricas:\n",
    "    report = classification_report(df_true_values[col], df_filled_values[col], output_dict=True)\n",
    "    acuracias_por_coluna[col] = report['accuracy']\n",
    "\n",
    "# Imprimir resultados\n",
    "print(\"Acurácia por Coluna:\")\n",
    "for col, acuracia in acuracias_por_coluna.items():\n",
    "    print(f\"{col}: {acuracia}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Acurácia por Coluna para Colunas Categóricas:\n",
      "Exercicio_Mais_Frequente: 1.0000\n",
      "Tipo_Verdura_Costuma_Comer: 1.0000\n",
      "Curso_Mais_Elevado: 1.0000\n",
      "\n",
      "Acurácia Geral para Colunas Categóricas: 1.0\n",
      "\n",
      "Relatório de Classificação por Coluna para Colunas Categóricas:\n",
      "Exercicio_Mais_Frequente\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     25925\n",
      "         1.0       1.00      1.00      1.00      7213\n",
      "        10.0       1.00      1.00      1.00       104\n",
      "        11.0       1.00      1.00      1.00       738\n",
      "        12.0       1.00      1.00      1.00      1234\n",
      "        13.0       1.00      1.00      1.00         7\n",
      "        14.0       1.00      1.00      1.00        64\n",
      "        15.0       1.00      1.00      1.00        36\n",
      "        16.0       1.00      1.00      1.00       241\n",
      "        17.0       1.00      1.00      1.00       323\n",
      "         2.0       1.00      1.00      1.00       337\n",
      "         3.0       1.00      1.00      1.00       621\n",
      "         4.0       1.00      1.00      1.00        74\n",
      "         5.0       1.00      1.00      1.00      1888\n",
      "         6.0       1.00      1.00      1.00       593\n",
      "         7.0       1.00      1.00      1.00       253\n",
      "         8.0       1.00      1.00      1.00       608\n",
      "         9.0       1.00      1.00      1.00       100\n",
      "\n",
      "    accuracy                           1.00     40359\n",
      "   macro avg       1.00      1.00      1.00     40359\n",
      "weighted avg       1.00      1.00      1.00     40359\n",
      "\n",
      "\n",
      "Tipo_Verdura_Costuma_Comer\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2786\n",
      "         1.0       1.00      1.00      1.00     29771\n",
      "         2.0       1.00      1.00      1.00      7476\n",
      "         3.0       1.00      1.00      1.00       326\n",
      "\n",
      "    accuracy                           1.00     40359\n",
      "   macro avg       1.00      1.00      1.00     40359\n",
      "weighted avg       1.00      1.00      1.00     40359\n",
      "\n",
      "\n",
      "Curso_Mais_Elevado\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00         7\n",
      "        10.0       1.00      1.00      1.00      9680\n",
      "        11.0       1.00      1.00      1.00       703\n",
      "        12.0       1.00      1.00      1.00      4698\n",
      "        13.0       1.00      1.00      1.00      1810\n",
      "        14.0       1.00      1.00      1.00       312\n",
      "        15.0       1.00      1.00      1.00       130\n",
      "         2.0       1.00      1.00      1.00       131\n",
      "         3.0       1.00      1.00      1.00       829\n",
      "         4.0       1.00      1.00      1.00       253\n",
      "         5.0       1.00      1.00      1.00      4957\n",
      "         6.0       1.00      1.00      1.00       968\n",
      "         7.0       1.00      1.00      1.00     14710\n",
      "         8.0       1.00      1.00      1.00       645\n",
      "         9.0       1.00      1.00      1.00       526\n",
      "\n",
      "    accuracy                           1.00     40359\n",
      "   macro avg       1.00      1.00      1.00     40359\n",
      "weighted avg       1.00      1.00      1.00     40359\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Calcular a acurácia e relatório de classificação para cada coluna categórica individualmente\n",
    "accuracy_por_coluna = {}\n",
    "classification_report_por_coluna = {}\n",
    "for col in cols_categoricas:\n",
    "    accuracy_por_coluna[col] = accuracy_score(df_true_values[col], df_filled_values[col])\n",
    "    classification_report_por_coluna[col] = classification_report(df_true_values[col], df_filled_values[col], output_dict=True)\n",
    "\n",
    "# Calcular a acurácia geral como a média das acurácias por coluna\n",
    "accuracy_geral = sum(accuracy_por_coluna.values()) / len(accuracy_por_coluna)\n",
    "\n",
    "# Imprimir a acurácia por coluna\n",
    "print(\"\\nAcurácia por Coluna para Colunas Categóricas:\")\n",
    "for col, accuracy in accuracy_por_coluna.items():\n",
    "    print(f\"{col}: {accuracy:.4f}\")\n",
    "\n",
    "# Imprimir a acurácia geral\n",
    "print(\"\\nAcurácia Geral para Colunas Categóricas:\", accuracy_geral)\n",
    "\n",
    "# Imprimir o relatório de classificação por coluna\n",
    "print(\"\\nRelatório de Classificação por Coluna para Colunas Categóricas:\")\n",
    "for col, report in classification_report_por_coluna.items():\n",
    "    print(col)\n",
    "    print(classification_report(df_true_values[col], df_filled_values[col]))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportando a base de dados \n",
    "df.to_csv(r\"C:\\Users\\maype\\OneDrive\\Área de Trabalho\\projects\\projeto-mineracao-de-dados\\Data\\base_tratada2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando Relatorio para Análises Gerais\n",
    "profile = ProfileReport(df, title=\"Profiling Report\")\n",
    "profile.to_file(r\"C:\\Users\\maype\\OneDrive\\Área de Trabalho\\projects\\projeto-mineracao-de-dados\\Vizualizaçoes\\EDA_sem_nulos_pns2019_depressao.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
